{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, lit, avg as spark_avg, stddev as spark_stddev\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10000000)\n",
    "pd.set_option('display.max_rows', 10000000)\n",
    "pd.set_option('display.width', 10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Spark Session for pseudo-distributed computing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Sharpe&Sortino_ratio').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading persisted Portfolio Yields dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_yield_window_path = '/data/core/fince/data/portfolioOptimization/portfolio_yield_window/'\n",
    "portfolio_yield_df = spark.read.parquet(portfolio_yield_window_path)\n",
    "portfolio_yield_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [portfolio_yield_df.select(lit(fund).alias('fund_name'), col(fund).alias('fund_yield')) for fund in portfolio_yield_df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll_df(*dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_yield_T = unionAll_df(*dataframes).cache()\n",
    "portfolio_yield_T.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Portfolio's Yield Transpose dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_path_mod3 = '/data/core/fince/data/portfolioOptimization/portfolio_yield_transpose/'\n",
    "\n",
    "print('\\nWriting parquets ...')\n",
    "portfolio_yield_T.repartition(1).write.mode('overwrite').parquet(writing_path_mod3)\n",
    "\n",
    "%time\n",
    "print('\\nSUCCESS \\nPARQUET DATA SAVED!')\n",
    "print('\\nNew root path tabla data:', writing_path_mod3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading persisted Portfolio Yields Transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_yield_T_path = '/data/core/fince/data/portfolioOptimization/portfolio_yield_transpose/'\n",
    "portfolio_yield_T_df = spark.read.parquet(portfolio_yield_T_path)\n",
    "len(portfolio_yield_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD = float(0.0)\n",
    "CASE = \"SCOTIA1\"\n",
    "\n",
    "negative_fund_yield = portfolio_yield_T_df.where(col(\"fund_yield\") < TRESHOLD)\n",
    "negative_fund_yield.where(col(\"fund_name\") == CASE).show(5)\n",
    "negative_fund_yield.where(col(\"fund_name\") == CASE)\\\n",
    "                   .describe(\"fund_yield\")\\\n",
    "                   .where((col(\"summary\") == \"min\")\n",
    "                        | (col(\"summary\") == \"max\")\n",
    "                        | (col(\"summary\") == \"stddev\")).show()\n",
    "print(\"after filtering negative yields we've got following parameters:\")\n",
    "print(\"{stddev:8.547E-5 , min: -1.872, max: -4.646}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_yield_df = portfolio_yield_T_df.groupBy(\"fund_name\").agg(spark_avg('fund_yield').alias(\"mean_yield\"))\n",
    "print(\"mean yield df:\")\n",
    "mean_yield_df.where(col(\"fund_name\") == CASE).show()\n",
    "\n",
    "stddev_negative_yield_df = negative_fund_yield.groupBy(\"fund_name\").agg(spark_stddev('fund_yield').alias(\"stddev_negative_yield\"))\n",
    "print(\"stddev negative yield df:\")\n",
    "stddev_negative_yield_df.where(col(\"fund_name\") == CASE).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sortino ratio:\n",
    "\n",
    "## **The Formula for the Sortino Ratio Is:**\n",
    "## Sortino Ratio = $\\frac{ R_p - r_f }{ \\sigma_d }$ \n",
    "## **Where:**\n",
    "### *R_p = Actual or expected portfolio return*\n",
    "### *r_f = Risk-free rate*\n",
    "### *sigma_d = Standard deviation of the downside*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortino_df = mean_yield_df.join(stddev_negative_yield_df, on=\"fund_name\", how=\"left\")\\\n",
    "                          .select(\"fund_name\", (col(\"mean_yield\") / col(\"stddev_negative_yield\")).alias(\"sortino_ratio\"))\\\n",
    "                          .na.fill(0.0)\n",
    "sortino_df.orderBy(col(\"sortino_ratio\")).show(5)\n",
    "sortino_df.where(col(\"fund_name\") == CASE).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpe ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_df = portfolio_yield_T_df.groupBy(\"fund_name\")\\\n",
    "                                .agg(spark_avg('fund_yield').alias(\"mean_yield\"), spark_stddev('fund_yield').alias(\"stddev_yield\"))\\\n",
    "                                .select(\"fund_name\", (col(\"mean_yield\") / col(\"stddev_yield\")).alias(\"sharpe_ratio\"))\n",
    "sharpe_df.orderBy(col(\"sharpe_ratio\").desc()).show(5)\n",
    "sharpe_df.where(col(\"fund_name\") == CASE).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joined Both Ratios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_ratios_df = sortino_df.join(sharpe_df, on=\"fund_name\", how=\"left\")\n",
    "joined_ratios_df.where(col(\"fund_name\") == CASE).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
