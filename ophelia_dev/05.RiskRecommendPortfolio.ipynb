{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize\n",
    "from com.ophelia.OpheliaVendata import OpheliaVendata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================================================================\n",
      "00:13:01.878 Ophelia [INFO] ¡Hi! My name is Ophelia\n",
      "00:13:01.878 Ophelia [INFO] I am an artificial assistant for machine learning applications in Spark\n",
      "00:13:01.878 Ophelia [INFO] Welcome to Ophelia Assisted Intelligence System (OAIS)\n",
      "00:13:01.878 Ophelia [INFO] V for Vendata...\n",
      "===================================================================================================\n",
      "\n",
      "                                 - By. Vendata-Gentleman Club -                            \n",
      "\n",
      "                   █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █\n",
      "                   █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █\n",
      "                   █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ █ █ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ █ █ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ █ █ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ █ █ ╬ ╬ █\n",
      "                   █ ╬ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ ╬ ╬ ╬ ╬ ╬ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ █ █ █ █ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ █ █ █ █ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ▓ ▓ ▓ ▓ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ▓ ▓ ▓ ▓ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ▓ ▓ ▓ ▓ ▓ ▓ ╬ ╬ █ ╬ ╬ ╬ █ ╬ ╬ ╬ █ ╬ ╬ ▓ ▓ ▓ ▓ ▓ ▓ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ▓ ▓ ▓ ▓ ╬ ╬ █ █ ╬ ╬ ╬ █ ╬ ╬ ╬ █ █ ╬ ╬ ▓ ▓ ▓ ▓ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ ╬ ╬ ╬ ╬ █ ╬ ╬ ╬ ╬ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ █ █ █ █ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ █ █ █ █ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █\n",
      "                   █ █ ╬ ╬ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ ╬ ╬ █ █\n",
      "                   █ █ ╬ ╬ █ █ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ █ █ ╬ ╬ █ █\n",
      "                   █ █ ╬ ╬ ▓ █ █ █ ╬ ╬ ╬ █ █ █ █ ╬ █ █ █ █ ╬ ╬ ╬ █ █ █ ▓ ╬ ╬ █ █\n",
      "                   █ █ █ ╬ ╬ ▓ ▓ █ █ █ █ █ █ █ ╬ ╬ ╬ █ █ █ █ █ █ █ ▓ ▓ ╬ ╬ █ █ █\n",
      "                   █ █ █ ╬ ╬ ╬ ╬ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ▓ ╬ ╬ ╬ ╬ █ █ █\n",
      "                   █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █\n",
      "                   █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █\n",
      "                   █ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ █\n",
      "                   █ █ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ █ █\n",
      "                   █ █ █ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ █ █ █\n",
      "                   █ █ █ █ █ █ █ █ █ ╬ ╬ ╬ ╬ ╬ █ █ █ ╬ ╬ ╬ ╬ ╬ █ █ █ █ █ █ █ █ █\n",
      "                   █ █ █ █ █ █ █ █ █ █ █ ╬ ╬ ╬ ╬ █ ╬ ╬ ╬ ╬ █ █ █ █ █ █ █ █ █ █ █\n",
      "                   █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █\n",
      "\n",
      "===================================================================================================\n",
      "00:13:01.878 Ophelia [INFO] Initializing OpheliaSpark Session\n",
      "00:13:10.933 Ophelia [INFO] OpheliaSpark Session Version: 3.0.0\n",
      "00:13:10.934 Ophelia [INFO] This Is: 'Risk Recommend Analysis' Project\n"
     ]
    }
   ],
   "source": [
    "ophelia = OpheliaVendata('Risk Recommend Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, max as spark_max, row_number, avg, count\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = ophelia.opSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_train_df = spark.read.parquet(\"data/ophelia/out/model/TrainPortfolio\", inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141931, 17)\n",
      "+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+-------------------+-------------------+---------------------+-------------------+-------------------+--------------------+--------------------+------------+--------------------------+-----------+----------------+\n",
      "|ret                 |stdev              |sharpe            |SCOTIAG             |SVIVE20390         |HSBC-80             |FINDE1400          |ACTIGOB401         |AXESMP402            |HSBC-70            |HSBCMP405          |SUR2042384          |INVEXMP407          |portfolio_id|model_date                |risk_bucket|information_date|\n",
      "+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+-------------------+-------------------+---------------------+-------------------+-------------------+--------------------+--------------------+------------+--------------------------+-----------+----------------+\n",
      "|0.03276294731988203 |0.06466918432427357|0.5066237909480553|0.029655610544278625|0.05873411828140106|0.012050849899143108|0.08932991980269187|0.16225169055822988|0.1800733058282388   |0.14122084857207517|0.14928381436992344|0.05229428333458693 |0.12510555880943103 |1000        |2020-09-28 21:44:47.414332|3.0        |2020-09-28      |\n",
      "|0.03816008353293257 |0.06677536025638994|0.5714695268795785|0.020309490945508615|0.01733236932359685|0.1282460909450767  |0.07467953661504627|0.21508911510282785|0.13626334072074786  |0.14829289006027574|0.12012063345614561|0.05847938796091414 |0.08118714486986033 |1001        |2020-09-28 21:44:47.414332|5.0        |2020-09-28      |\n",
      "|0.03750018195408164 |0.07130290970602984|0.5259277932511971|0.04775060198037269 |0.10950908325859847|0.10985627832293918 |0.12720441245209219|0.11284894079821152|0.0028200661677799358|0.11104308387496276|0.18981553348911898|0.16312280207069005 |0.026029197585234275|1002        |2020-09-28 21:44:47.414332|3.0        |2020-09-28      |\n",
      "|0.03733635281922839 |0.07940251919796734|0.4702162248296044|0.054478205897753956|0.11269017801310163|0.13370176740722609 |0.08534248401251582|0.14161412587560596|0.0352844820526305   |0.10271842838807672|0.1014132309136935 |0.08694954981993738 |0.14580754761945838 |1003        |2020-09-28 21:44:47.414332|1.0        |2020-09-28      |\n",
      "|0.041329982983103614|0.07836645463114204|0.5273938087110999|0.16061732493755038 |0.07883656133946014|0.007457183140127319|0.10123451569183452|0.13121564590046897|0.0018709571918127156|0.19623790460467413|0.21637540237566158|0.033307695235659594|0.0728468095827508  |1004        |2020-09-28 21:44:47.414332|4.0        |2020-09-28      |\n",
      "+--------------------+-------------------+------------------+--------------------+-------------------+--------------------+-------------------+-------------------+---------------------+-------------------+-------------------+--------------------+--------------------+------------+--------------------------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- ret: double (nullable = true)\n",
      " |-- stdev: double (nullable = true)\n",
      " |-- sharpe: double (nullable = true)\n",
      " |-- SCOTIAG: double (nullable = true)\n",
      " |-- SVIVE20390: double (nullable = true)\n",
      " |-- HSBC-80: double (nullable = true)\n",
      " |-- FINDE1400: double (nullable = true)\n",
      " |-- ACTIGOB401: double (nullable = true)\n",
      " |-- AXESMP402: double (nullable = true)\n",
      " |-- HSBC-70: double (nullable = true)\n",
      " |-- HSBCMP405: double (nullable = true)\n",
      " |-- SUR2042384: double (nullable = true)\n",
      " |-- INVEXMP407: double (nullable = true)\n",
      " |-- portfolio_id: long (nullable = true)\n",
      " |-- model_date: timestamp (nullable = true)\n",
      " |-- risk_bucket: double (nullable = true)\n",
      " |-- information_date: date (nullable = true)\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|sharpe             |\n",
      "+-------+-------------------+\n",
      "|count  |141931             |\n",
      "|mean   |0.5215089382733314 |\n",
      "|stddev |0.03811209884502561|\n",
      "|min    |0.46644887498650695|\n",
      "|max    |0.7064306901193952 |\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(portfolio_train_df.shape)\n",
    "portfolio_train_df.show(5, False)\n",
    "portfolio_train_df.printSchema()\n",
    "portfolio_train_df.describe(\"sharpe\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------------------+-------------------+--------------------+-------------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+--------------------+------------+--------------------------+-----------+----------------+\n",
      "|ret                 |stdev              |sharpe            |SCOTIAG            |SVIVE20390          |HSBC-80            |FINDE1400           |ACTIGOB401         |AXESMP402           |HSBC-70             |HSBCMP405          |SUR2042384         |INVEXMP407          |portfolio_id|model_date                |risk_bucket|information_date|\n",
      "+--------------------+-------------------+------------------+-------------------+--------------------+-------------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+--------------------+------------+--------------------------+-----------+----------------+\n",
      "|0.04078633279938808 |0.08387367832475978|0.4862828674505363|0.16715074995872348|0.08932423814860127 |0.10948500154228814|0.10710751328926085 |0.09617092715958864|0.12229260578735705 |0.013069204878482387|0.0962092582914066 |0.05360606454957097|0.14558443639472055 |17179885790 |2020-09-28 21:44:47.414332|1.0        |2020-09-28      |\n",
      "|0.03512244975459587 |0.06951463208977818|0.5052526165891983|0.06436082565114758|0.08226558851847095 |0.17767008772430762|0.012156450373461804|0.12436935809565614|0.0975382547768867  |0.07281297569692048 |0.15245912679793747|0.1443965733755326 |0.07197075898967864 |51539609045 |2020-09-28 21:44:47.414332|2.0        |2020-09-28      |\n",
      "|0.03650603535952865 |0.06940735831556465|0.5259677971541836|0.14632399312058492|0.037754143616104345|0.08930409886075315|0.12180152332285216 |0.07043003712418063|0.051501870821782855|0.08503698275490569 |0.15698059265705072|0.15813139447075508|0.08273536325103047 |15106       |2020-09-28 21:44:47.414332|3.0        |2020-09-28      |\n",
      "|0.03488871146035936 |0.06302738918422876|0.5535484162033084|0.18357100943086677|0.08238601612080845 |0.03424911519990121|0.09551603341562905 |0.12461730063442868|0.13079974346460077 |0.1486327511164435  |0.00521170833226237|0.11254781268715477|0.08246850959790439 |14306       |2020-09-28 21:44:47.414332|4.0        |2020-09-28      |\n",
      "|0.047899836737618176|0.06780543004087568|0.7064306901193952|0.1031387519479163 |0.006924887801652816|0.02753289274821339|0.24001519985195563 |0.2645721065696767 |0.033296951953673826|0.060382353808673364|0.03713213780719347|0.21868569999190574|0.008319017519138742|17179888732 |2020-09-28 21:44:47.414332|5.0        |2020-09-28      |\n",
      "+--------------------+-------------------+------------------+-------------------+--------------------+-------------------+--------------------+-------------------+--------------------+--------------------+-------------------+-------------------+--------------------+------------+--------------------------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_max_sharpe = portfolio_train_df.join(\n",
    "    portfolio_train_df.groupBy('risk_bucket').agg(spark_max('sharpe').alias('max_sharpe')),\n",
    "    on=[col('sharpe') == col('max_sharpe')],\n",
    "    how='left_semi').orderBy('risk_bucket')\n",
    "filter_max_sharpe.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_class_df = spark.read.parquet(\"data/ophelia/out/model/RiskClassifier\")\n",
    "print(risk_class_df.shape)\n",
    "risk_class_df.show(5, False)\n",
    "risk_class_df.groupBy('risk_label', 'risk_label_id').count().orderBy(col('risk_label_id')).show(5, False)\n",
    "risk_class_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_class_col_prune = [\"information_date\", \"model_date\"]\n",
    "portfolio_train_col_prune = [\"information_date\", \"model_date\"]\n",
    "join_over_col = [col(\"risk_label_id\")==col(\"risk_bucket\")]\n",
    "join_col_prune = [\"risk_bucket\", \"risk_label_id\"]\n",
    "\n",
    "portfolio_base_table = risk_class_df.drop(*risk_class_col_prune)\\\n",
    "                                    .join(filter_max_sharpe.drop(*portfolio_train_col_prune), on=join_over_col, how=\"inner\")\\\n",
    "                                    #.drop(*join_col_prune)\n",
    "portfolio_base_table.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(portfolio_base_table.shape)\n",
    "portfolio_base_table.printSchema()\n",
    "portfolio_base_table.groupBy('risk_bucket', 'risk_label_id', 'risk_label', 'portfolio_id')\\\n",
    "                    .agg(count('risk_label'), avg('sharpe'), avg('stdev'), \n",
    "                         avg('ret')).orderBy('avg(sharpe)').show()\n",
    "portfolio_base_table.groupBy(\"portfolio_id\").count().show()\n",
    "portfolio_base_table.orderBy('customer_id').show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembled = VectorAssembler(inputCols=['ret', 'stdev', 'sharpe'], outputCol='features').transform(portfolio_base_table)\n",
    "vec_assembled.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans().setK(5).setSeed(1)\n",
    "model_kmeans = kmeans.fit(vec_assembled)\n",
    "transformed = model_kmeans.transform(vec_assembled)\n",
    "transformed.groupBy(\"prediction\")\\\n",
    "           .agg(count('risk_label'), count('prediction'), avg('sharpe'), avg('stdev'), avg('ret')).orderBy('avg(sharpe)').show()\n",
    "transformed.groupBy(\"prediction\", 'risk_label')\\\n",
    "           .agg(count('risk_label'), count('prediction'), avg('sharpe'), avg('stdev'), avg('ret')).orderBy('avg(sharpe)').show()\n",
    "transformed.groupBy(\"prediction\", 'risk_label', 'risk_label_id', 'risk_bucket', 'portfolio_id')\\\n",
    "           .agg(count('risk_label'), count('prediction'), avg('sharpe'), avg('stdev'), avg('ret')).orderBy('avg(sharpe)').show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cambiar el index del benchmark\n",
    "- hacer back-testing con datos actuales\n",
    "- simular portafolios con constraint min 10% por fondo\n",
    "- revisar que porcentaje de equity tiene cada portafolio\n",
    "- pendiente definir constraint de equity por portafolio perfil\n",
    "- nuevo cuestionario de perfilamiento\n",
    "- pendiente definir benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we can see cluster to verify that cluster splitting was difined correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(transformed)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "# Shows the result.\n",
    "centers = model_kmeans.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_zero = transformed.where(col('prediction') == '0').toNumpyArray()\n",
    "cluster_one = transformed.where(col('prediction') == '1')\n",
    "cluster_two = transformed.where(col('prediction') == '2')\n",
    "cluster_three = transformed.where(col('prediction') == '3')\n",
    "cluster_four = transformed.where(col('prediction') == '4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter1 = dict(\n",
    "    mode = \"markers\",\n",
    "    name = \"Cluster 1\",\n",
    "    type = \"scatter3d\",    \n",
    "    x = cluster_zero.as_matrix()[:,0], y = cluster_zero.as_matrix()[:,1], z = cluster_zero.as_matrix()[:,2],\n",
    "    marker = dict( size=2, color='green')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "class Kmeans:\n",
    "    '''Implementing Kmeans algorithm.'''\n",
    "\n",
    "    def __init__(self, n_clusters, max_iter=100, random_state=123):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def initializ_centroids(self, X):\n",
    "        np.random.RandomState(self.random_state)\n",
    "        random_idx = np.random.permutation(X.shape[0])\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "        return centroids\n",
    "\n",
    "    def compute_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def compute_distance(self, X, centroids):\n",
    "        distance = np.zeros((X.shape[0], self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            row_norm = norm(X - centroids[k, :], axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "\n",
    "    def find_closest_cluster(self, distance):\n",
    "        return np.argmin(distance, axis=1)\n",
    "\n",
    "    def compute_sse(self, X, labels, centroids):\n",
    "        distance = np.zeros(X.shape[0])\n",
    "        for k in range(self.n_clusters):\n",
    "            distance[labels == k] = norm(X[labels == k] - centroids[k], axis=1)\n",
    "        return np.sum(np.square(distance))\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.centroids = self.initializ_centroids(X)\n",
    "        for i in range(self.max_iter):\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X, old_centroids)\n",
    "            self.labels = self.find_closest_cluster(distance)\n",
    "            self.centroids = self.compute_centroids(X, self.labels)\n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                break\n",
    "        self.error = self.compute_sse(X, self.labels, self.centroids)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        distance = self.compute_distance(X, old_centroids)\n",
    "        return self.find_closest_cluster(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = portfolio_train_df.select('ret', 'stdev', 'sharpe').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import pandas as pd\n",
    "from sklearn.datasets.samples_generator import (make_blobs,\n",
    "                                                make_circles,\n",
    "                                                make_moons)\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "X_std = StandardScaler().fit_transform(df)\n",
    "\n",
    "# Run local implementation of kmeans\n",
    "km = Kmeans(n_clusters=2, max_iter=100)\n",
    "km.fit(X_std)\n",
    "centroids = km.centroids\n",
    "\n",
    "# Plot the clustered data\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "plt.scatter(X_std[km.labels == 0, 0], X_std[km.labels == 0, 1],\n",
    "            c='green', label='cluster 1')\n",
    "plt.scatter(X_std[km.labels == 1, 0], X_std[km.labels == 1, 1],\n",
    "            c='blue', label='cluster 2')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=300,\n",
    "            c='r', label='centroid')\n",
    "plt.legend()\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-5, 5])\n",
    "plt.xlabel('Eruption time in mins')\n",
    "plt.ylabel('Waiting time to next eruption')\n",
    "plt.title('Visualization of clustered data', fontweight='bold')\n",
    "ax.set_aspect('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "list_k = list(range(1, 10))\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km.fit(X_std)\n",
    "    sse.append(km.inertia_)\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pd.DataFrame(centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ophelia",
   "language": "python",
   "name": "ophelia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
