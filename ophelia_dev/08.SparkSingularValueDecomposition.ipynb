{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_subarea.output_text.output_stream.output_stdout > pre {\n",
       "    width:max-content;\n",
       "}\n",
       ".p-Widget.jp-RenderedText.jp-OutputArea-output > pre {\n",
       "   width:max-content;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_subarea.output_text.output_stream.output_stdout > pre {\n",
    "    width:max-content;\n",
    "}\n",
    ".p-Widget.jp-RenderedText.jp-OutputArea-output > pre {\n",
    "   width:max-content;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import install_ophelia\n",
    "\n",
    "from ophelia.spark.OpheliaMain import Ophelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:13:49.007 Ophelia [TAPE] +---------------------------------------------------------------------+\n",
      "22:13:49.008 Ophelia [INFO] | My name is Ophelia Vendata                                          |\n",
      "22:13:49.008 Ophelia [INFO] | I am an artificial assistant for data mining & ML engine with spark |\n",
      "22:13:49.008 Ophelia [INFO] | Welcome to Ophelia spark miner engine                               |\n",
      "22:13:49.008 Ophelia [INFO] | Lib Version Ophelia.dev1.0                                          |\n",
      "22:13:49.008 Ophelia [WARN] | V for Vendata...                                                    |\n",
      "22:13:49.008 Ophelia [TAPE] +---------------------------------------------------------------------+\n",
      "22:13:49.008 Ophelia [WARN] Initializing Spark Session\n",
      "22:13:58.168 Ophelia [INFO] Spark Version: 3.0.0\n",
      "22:13:58.168 Ophelia [INFO] This Is: 'Spark Singular Value Decomposition' App\n"
     ]
    }
   ],
   "source": [
    "ophelia = Ophelia(\"Spark Singular Value Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = ophelia.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_price_path = 'data/staging/benchmark/close_day_price'\n",
    "day_price_df = spark.read.parquet(day_price_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The calculation is performed using Singular Value Decomposition (SVD). The SVD of any $m x n$ array is calculated as follows:\n",
    "\n",
    "$$A = U \\sum V^{T}$$\n",
    "\n",
    "### Where $U$ is an orthogonal matrix $m x m$ whose columns are the eigenvectors (eigenvectors) of $AA^{T}$, $V$ is an orthogonal matrix $n x n$ whose columns are the eigenvectors of $A^{T}A$, and $\\sum$ is a diagonal matrix $m x n$ and its values are zero except along the diagonal.\n",
    "\n",
    "### When applying PCA, we have to center our data, that is, depending on its nature, we may need to standardize (make each characteristic have a variance of 1 and a mean of 0). If the columns are on different scales like the year, the temperature, the concentration of carbon dioxide, we have to standardize the data. If the data is on the same drive, on the other hand, standardization can lead to the loss of important information. In the first case, when the columns are in the same unit and on a similar scale, we use the covariance matrix for SVD but when the units are different since we standardize the data, we use the correlation matrix.\n",
    "\n",
    "### The principal components (PC) are the matrix product of the original data and the matrix $V$, which is equal to the product of the matrices $U$ and $\\sum$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Value Decomposition analysis.\n",
    "\n",
    "### At the very first step we have to take two input parameters, one is called ___n___, that refers to the total count of rows in dataframe. The second refers to the total number of columns called _features_, i.e. ___d___. Thus we will find this matrix with _(n, d)_ dimensions.\n",
    "\n",
    "### What do we want to confirm is that every vector $\\vec{V_i}$ of length d is a _dense vector_. This is, we want to get full vectors without any null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's standarize this dense vectors of length __d__ with the _Standard Scaler_ method, i.e. Mean and Standard Deviation are involved for this standarization (re-scaled vectors of features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to compute SVD we have to transfrom spark-dataframe to a matrix object with indexed elements from scaled features, for that, we will use _IndexedRowMatrix_ method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's compute the singular value decomposition of the IndexedRowMatrix. The given row matrix $A$ of dimension __$(m x n)$__ is decomposed into\n",
    "### _$$U s V^{T}$$ where:_\n",
    "* $U$: $(m x k)$ __*left singular vectors* is a IndexedRowMatrix whose columns are the eigenvectors of $(A X A')$__\n",
    "* $s$: __DenseVector consisting of square root of the eigenvalues *singular values* in descending order.__\n",
    "* $V$: $(n x k)$ __*right singular vectors* is a Matrix whose columns are the eigenvectors of $(A' X A)$__\n",
    "\n",
    "### This _computeSVD_ interface recieves two main arguments:\n",
    "* $k$, for $k^{th}$ int number, thus each element $k$ = {${k_{i} \\in \\Bbb R}$}\n",
    "* $U$, with _computeU_ boolean __True__, whether or not to compute $U$. If set to be __True__, then $U$ is computed by $A  V  s^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ophelia.spark.ml.unsupervised.FeatureExtraction import SingularValueDecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:32:11.097 Ophelia [INFO] Build Vector Assembler\n",
      "22:32:11.440 Ophelia [INFO] Feature Vector Assembling\n",
      "22:32:11.471 Ophelia [INFO] Feature Standard Normalization\n",
      "22:32:14.226 Ophelia [INFO] Indexing RDD Row Matrix\n",
      "22:32:17.770 Ophelia [TAPE] +-------------------------------------+\n",
      "22:32:17.770 Ophelia [WARN] | Compute SVD With K=10, d=71, n=3062 |\n",
      "22:32:17.770 Ophelia [TAPE] +-------------------------------------+\n",
      "22:32:18.036 Ophelia [INFO] Compute Variance For Each Component\n",
      "22:32:18.036 Ophelia [TAPE] +------------------------------------------+\n",
      "22:32:18.036 Ophelia [WARN] | Components Over 0.75 Of The Variance k=2 |\n",
      "22:32:18.036 Ophelia [WARN] | Components Over 0.85 Of The Variance k=3 |\n",
      "22:32:18.036 Ophelia [WARN] | Components Over 0.95 Of The Variance k=5 |\n",
      "22:32:18.040 Ophelia [TAPE] +------------------------------------------+\n",
      "22:32:18.047 Ophelia [INFO] Set Components Over 0.95 Of The Variance k=5\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|            features|     scaled_features|      5_pca_features|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  0|[225.14,14.2458,2...|[-0.9556082868159...|[7.5625736426859,...|\n",
      "|  1|[242.12,14.5533,3...|[-0.4591418045635...|[6.33529602606563...|\n",
      "|  2|[211.66,12.5381,2...|[-1.3497406885097...|[8.54644074554026...|\n",
      "|  3|[222.6,14.3739,26...|[-1.0298735909926...|[7.47841724708471...|\n",
      "|  4|[214.11,13.232,26...|[-1.2781068321188...|[8.04026564489551...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_selection = day_price_df.drop('close_timestamp', 'close_date', 'close_year')\n",
    "\n",
    "svd_df = SingularValueDecomposition(k=10).transform(feature_selection)\n",
    "svd_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ophelia",
   "language": "python",
   "name": "ophelia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
